{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jerichoo/jupyter_py3/lib/python2.7/site-packages/')\n",
    "from joblib import Parallel, delayed\n",
    "sys.path.insert(0,'./moments/moments/utils')\n",
    "sys.path.insert(0,'./moments/')\n",
    "import moments.core.ppmdir\n",
    "import fpp\n",
    "    \n",
    "\n",
    "def reformat_hv(ftype,dump,info): \n",
    "    print ftype, dump\n",
    "    for file in info.source.get_dumpfiles(ftype, dump):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        RBO_in_ftype = None\n",
    "        for key, value in info.RBO_input_map.items():\n",
    "            if ftype in key:\n",
    "                RBO_in_ftype = value\n",
    "                break\n",
    "        if RBO_in_ftype is not None:\n",
    "            nbytes = os.path.getsize(file)\n",
    "            nbytes_theoretical = (info.resolutionx*info.resolutiony*info.resolutionz)/info.nteams\n",
    "            out_file = info.hv_processing_format.format(ftype=ftype, RBO_in_ftype=RBO_in_ftype, dump=dump, ext=ext)\n",
    "\n",
    "            if ftype == 'FV-hires':\n",
    "                nbytes_theoretical *= info.nteams # don't know if this is true\n",
    "            if nbytes != nbytes_theoretical:\n",
    "                if nbytes < nbytes_theoretical:\n",
    "                    print nbytes, '> ', nbytes_theoretical, ftype, dump\n",
    "                    print 'this is not the right size'\n",
    "                    break\n",
    "                if nbytes > nbytes_theoretical: \n",
    "                    print nbytes, '> ', nbytes_theoretical, ftype, dump\n",
    "                    out_dir = os.path.dirname(out_file)\n",
    "                    if not os.path.exists(out_dir):\n",
    "                        os.makedirs(out_dir)\n",
    "\n",
    "                    truncate_command = [\"tail\",\"-c\",str(nbytes_theoretical),file,\">\",out_file]\n",
    "                    command = subprocess.Popen(' '.join(truncate_command), shell=True)\n",
    "                    command.wait()\n",
    "            else:\n",
    "                _copy_file(file, out_file)\n",
    "        else:\n",
    "            print 'cannot convert {ftype} files into hv'.format(ftype=ftype)\n",
    "            break\n",
    "\n",
    "    for RBO_key in info.RBO_input_map.keys():         \n",
    "        if ftype in RBO_key:\n",
    "            settings = dict((key, info.source_code_definitions.get(key, value)) for key, value in info.RBO_default.items())\n",
    "            settings.update(info.RBO_settings[RBO_key])\n",
    "\n",
    "            code = fpp.define(info.RBO_source, **settings)\n",
    "            with open(info.hv_source_format.format(ftype=ftype,dump=dump), \"w\") as fout:\n",
    "                fout.write(code)\n",
    "\n",
    "            ftype_RBO_source = info.hv_source_format.format(ftype=ftype,dump=dump)\n",
    "            ftype_RBO, _ = os.path.splitext(ftype_RBO_source)\n",
    "            compile = subprocess.Popen([\"ifort\", ftype_RBO_source] + info.RBO_compile_flags + [ftype_RBO])\n",
    "            compile.wait()\n",
    "\n",
    "            processing_dir = os.path.dirname(info.hv_processing_format.format(ftype=ftype, RBO_in_ftype=\"\", dump=\"\", ext=\"\"))\n",
    "            RBO_command = [ftype_RBO, str(int(dump)), str(int(dump))]\n",
    "\n",
    "            RBO_compute = subprocess.Popen(RBO_command, cwd=processing_dir)\n",
    "            RBO_compute.wait()\n",
    "\n",
    "            bob2hv_ftype = None\n",
    "            for key, value in info.bob2hv_input_map.items():\n",
    "                if ftype in key:\n",
    "                    bob2hv_ftype = value\n",
    "                    break\n",
    "\n",
    "            if bob2hv_ftype is not None:                \n",
    "                resolutionx = info.source_code_definitions[\"nnxteams\"]*info.source_code_definitions[\"nntxbricks\"]*info.source_code_definitions[\"nnnnx\"]\n",
    "                resolutiony = info.source_code_definitions[\"nnyteams\"]*info.source_code_definitions[\"nntybricks\"]*info.source_code_definitions[\"nnnny\"]\n",
    "                resolutionz = info.source_code_definitions[\"nnzteams\"]*info.source_code_definitions[\"nntzbricks\"]*info.source_code_definitions[\"nnnnz\"]\n",
    "                if not any([ftype in type for type in info.is_hires]):\n",
    "                    resolutionx = int(resolutionx/2.0)\n",
    "                    resolutiony = int(resolutiony/2.0)\n",
    "                    resolutionz = int(resolutionz/2.0)\n",
    "                    RBO_file = info.hv_processing_format.format(ftype=ftype, RBO_in_ftype=bob2hv_ftype, dump=dump, ext=\".bobaaa\")\n",
    "                else:\n",
    "                    RBO_file = info.hv_processing_format.format(ftype=ftype, RBO_in_ftype=bob2hv_ftype, dump=dump, ext=\".bob8aaa\")\n",
    "            \n",
    "                bob2hv_command = [info.bob2hv_path, str(resolutionx), str(resolutiony), str(int(resolutionz/2.0)), RBO_file, \"-t\",\n",
    "                                  str(info.source_code_definitions[\"nnxteams\"]), str(info.source_code_definitions[\"nnyteams\"]), str(2*info.source_code_definitions[\"nnzteams\"]), \"-s\", \"128\"]\n",
    "\n",
    "                bob2hv = subprocess.Popen(bob2hv_command, cwd=processing_dir)\n",
    "                bob2hv.wait()\n",
    "\n",
    "                hv_file, _ = os.path.splitext(RBO_file)\n",
    "                try:\n",
    "                    _move_file(hv_file + \".hv\", info.hv_format.format(ftype=ftype, dump=dump, ext=\".hv\"))\n",
    "                except IOError as error:\n",
    "                    print 'No .hv file was made for {ftype}'.format(ftype=info.hv_format.format(ftype=ftype, dump=dump, ext=\".hv\"))\n",
    "                    print 'Either {RBO} or {bob} command failed'.format(RBO=RBO_command,bob =bob2hv_command)\n",
    "                    \n",
    "def _copy_file(source, target):\n",
    "    target_dir = os.path.dirname(target)\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    try:\n",
    "        if not os.path.exists(target):\n",
    "            shutil.copy(source, target)\n",
    "            pass\n",
    "    except IOError as error:\n",
    "        print(error)\n",
    "\n",
    "def _move_file(source, target):\n",
    "    target_dir = os.path.dirname(target)\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    if not os.path.exists(target):\n",
    "        shutil.move(source, target)\n",
    "\n",
    "class reformation_info(object):\n",
    "    \n",
    "    def __init__(self,source_dir,target_dir,all_files=False,max_dumps=None):\n",
    "        \n",
    "        #RBO: ReformatBigOutput\n",
    "        self.max_dumps = max_dumps\n",
    "        self.all_files = all_files\n",
    "\n",
    "        if isinstance(source_dir, str):\n",
    "            self.source_dir = os.path.abspath(source_dir) + \"/\"\n",
    "            self.source = moments.core.ppmdir.get_ppmdir(source_dir, all_files)\n",
    "        else:\n",
    "            self.source = source_dir\n",
    "            self.source_dir = source._dir\n",
    "\n",
    "        self.target_dir = os.path.abspath(target_dir) + \"/\"\n",
    "\n",
    "        self.profile_format = self.target_dir + \"{ftype}/{ftype}-{dump}{ext}\"\n",
    "        self.bobfile_format = self.target_dir + \"{ftype}/{dump}{ext}\"\n",
    "        self.ppmin_format = self.target_dir + \"post/{fname}\"\n",
    "        self.hv_format = self.target_dir + \"HV/{ftype}/{dump}{ext}\"\n",
    "        self.hv_processing_format = self.target_dir + \"HV_processing/{ftype}/{RBO_in_ftype}-{dump}{ext}\"\n",
    "        self.hv_source_format = self.target_dir + \"HV_processing/{ftype}{dump}_xreformat64_all.F\"\n",
    "\n",
    "        self.RBO_source = pkg_resources.resource_string(\"moments.utils\", \"/bin/ReformatBigOutputargs.F\")\n",
    "        self.RBO_compile_flags = [\"-mcmodel=medium\", \"-i-dynamic\", \"-tpp7\", \"-xT\", \"-fpe0\",\n",
    "                             \"-w\", \"-ip\", \"-Ob2\", \"-pc32\", \"-i8\", \"-auto\", \"-fpp2\", \"-o\"]\n",
    "\n",
    "        self.RBO_input_map = {\"FVandMoms\":\"FVandMoms48\",\n",
    "                         \"FV-hires\":\"FV-hires01\",\n",
    "                         \"TanhUY\":\"TanhUY--001\",\n",
    "                         \"TanhDivU\":\"TanhDivU-01\",\n",
    "                         \"Lg10Vort\":\"Lg10Vort-01\",\n",
    "                         \"Lg10ENUCbyP\":\"Lg10ENUCbyP\"}\n",
    "\n",
    "        self.RBO_default = {\"isBoB8\":0, \"isBoB\":0, \"isMom\":0, \"isvort\":0,\n",
    "                       \"isdivu\":0, \"isuy\":0, \"isenuc\":0, \"nnxteams\":0,\n",
    "                       \"nnyteams\":0, \"nnzteams\":0, \"nntxbricks\":0,\n",
    "                       \"nntybricks\":0, \"nntzbricks\":0, \"nnnnx\":0,\n",
    "                       \"nnnny\":0, \"nnnnz\":0}\n",
    "\n",
    "        self.RBO_settings = {\"FVandMoms\":{\"isMom\":1},\n",
    "                        \"FV-hires\":{\"isBoB8\":1},\n",
    "                        \"TanhUY\":{\"isBoB\":1, \"isuy\":1},\n",
    "                        \"TanhDivU\":{\"isBoB\":1, \"isdivu\":1},\n",
    "                        \"Lg10Vort\":{\"isBoB\":1, \"isvort\":1},\n",
    "                        \"Lg10ENUCbyP\":{\"isBoB\":1, \"isenuc\":1}}\n",
    "\n",
    "        self.bob2hv_path = os.path.abspath(pkg_resources.resource_filename(\"moments.utils\", \"/bin/bob2hv\"))\n",
    "\n",
    "        self.is_hires = [\"FV-hires\"]\n",
    "\n",
    "        self.bob2hv_input_map = {\"FVandMoms\":\"FVandMomt48\",\n",
    "                            \"FV-hires\":\"FV-hiret01\",\n",
    "                            \"TanhUY\":\"TanhUY-0001\",\n",
    "                            \"TanhDivU\":\"TanhDivV-01\",\n",
    "                            \"Lg10Vort\":\"Lg10Voru-01\",\n",
    "                            \"Lg10ENUCbyP\":\"Lg10ENVCbyP\"}\n",
    "\n",
    "        self.profiles = []\n",
    "        self.bobfiles = []\n",
    "        self.ppminfiles = []\n",
    "        self.hvfiles = []\n",
    "\n",
    "        #analyze PPM2F source code\n",
    "        for file in self.source.get_source_code():\n",
    "            print file[-4:], source_dir[-2:]\n",
    "            if file.endswith(source_dir[-2:]+'.F'):\n",
    "                print file\n",
    "                source_code = file\n",
    "                break\n",
    "                \n",
    "        if 'source_code' not in locals():\n",
    "            source_code = self.source.get_source_code()[0]\n",
    "            \n",
    "        self.source_code_definitions = fpp.preprocess(source_code)\n",
    "        if (\"nnzteams\" in self.source_code_definitions) and (\"nnxteams\" not in self.source_code_definitions):\n",
    "            self.source_code_definitions[\"nnxteams\"] = self.source_code_definitions[\"nnzteams\"]\n",
    "\n",
    "        if (\"nntzbricks\" in self.source_code_definitions) and (\"nntxbricks\" not in self.source_code_definitions):\n",
    "            self.source_code_definitions[\"nntxbricks\"] = self.source_code_definitions[\"nntzbricks\"]\n",
    "\n",
    "        if (\"nnnnz\" in self.source_code_definitions) and (\"nnnnx\" not in self.source_code_definitions):\n",
    "            self.source_code_definitions[\"nnnnx\"] = self.source_code_definitions[\"nnnnz\"] \n",
    "        #move files into HV_processing\n",
    "        self.resolutionx = self.source_code_definitions[\"nnxteams\"]*self.source_code_definitions[\"nntxbricks\"]\\\n",
    "            *self.source_code_definitions[\"nnnnx\"]\n",
    "        self.resolutiony = self.source_code_definitions[\"nnyteams\"]*self.source_code_definitions[\"nntybricks\"]\\\n",
    "            *self.source_code_definitions[\"nnnny\"]\n",
    "        self.resolutionz = self.source_code_definitions[\"nnzteams\"]*self.source_code_definitions[\"nntzbricks\"]\\\n",
    "            *self.source_code_definitions[\"nnnnz\"]\n",
    "        self.nteams = self.source_code_definitions[\"nnxteams\"]*self.source_code_definitions[\"nnyteams\"]\\\n",
    "            *self.source_code_definitions[\"nnzteams\"]\n",
    "        \n",
    "        print self.resolutionx, self.nteams\n",
    "        \n",
    "        self.profiles = self.source.get_profile_types()\n",
    "        for ftype in self.source.get_bobfile_types():\n",
    "            if \"FVandMoms\" in ftype:\n",
    "                self.bobfiles.append(ftype)\n",
    "            else:\n",
    "                self.hvfiles.append(ftype)\n",
    "        self.ppminfiles = self.source.get_ppminfile_types()\n",
    "    \n",
    "def copy_source_code(info):\n",
    "    \n",
    "    for file in info.source.get_source_code() + info.source.get_compile_script() + info.source.get_jobscript() + info.source.get_other_files():\n",
    "        fname = file.replace(info.source_dir, \"\")\n",
    "        _copy_file(file, info.target_dir + fname)\n",
    "        \n",
    "def copy_profiles(info,ftype,dump):\n",
    "    \n",
    "    for file in info.source.get_dumpfiles(ftype, dump):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        _copy_file(file, info.profile_format.format(ftype=ftype, dump=dump, ext=ext))\n",
    "                \n",
    "def copy_bobfiles(info,ftype,dump):\n",
    "    \n",
    "    for file in info.source.get_dumpfiles(ftype, dump):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        _copy_file(file, info.bobfile_format.format(ftype=ftype, dump=dump, ext=ext))\n",
    "                \n",
    "def copy_ppminfiles(info):\n",
    "    \n",
    "    for ftype in info.ppminfiles:\n",
    "        for i, dump in enumerate(info.source.get_dumps(ftype)):\n",
    "            if info.max_dumps is not None:\n",
    "                if i == info.max_dumps:\n",
    "                    break\n",
    "            for file in info.source.get_dumpfiles(ftype, dump):\n",
    "                fname = os.path.basename(file)\n",
    "                _copy_file(file, info.ppmin_format.format(fname=fname))\n",
    "\n",
    "def reformat_parallel(source_dir,target_dir,all_files=False,max_dumps=None):\n",
    "    \n",
    "    info = reformation_info(source_dir,target_dir,all_files=False,max_dumps=None)\n",
    "    \n",
    "    #copy_only(info)\n",
    "    \n",
    "    copy_source_code(info)\n",
    "    copy_ppminfiles(info)\n",
    "    \n",
    "    num_cores = 4 #mp.cpu_count() #this always returns 32\n",
    "        \n",
    "    # Running the copy process in parallel\n",
    "    Parallel(n_jobs=num_cores)(\n",
    "        delayed(copy_profiles)(info,ftype,ndump) for ftype in info.profiles\\\n",
    "        for ndump in info.source.get_dumps(ftype))\n",
    "    \n",
    "    Parallel(n_jobs=num_cores)(\n",
    "        delayed(copy_bobfiles)(info,ftype,ndump) for ftype in info.bobfiles\\\n",
    "        for ndump in info.source.get_dumps(ftype))\n",
    "    \n",
    "    # Running the hv transformation in parallel\n",
    "    Parallel(n_jobs=num_cores)(\n",
    "        delayed(reformat_hv)(ftype,ndump,info) for ftype in info.hvfiles\\\n",
    "        for ndump in info.source.get_dumps(ftype))\n",
    "                        \n",
    "    shutil.rmtree(os.path.dirname(info.hv_source_format.format(ftype=\"\",dump=\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J5.F s2\n",
      "Warning: Evaluation of preprocessor directive failed.\n",
      "\t\"#define nnbsmax nnbuckets/5\"\n",
      "Warning: Evaluation of preprocessor macros not implemented.\n",
      "\t\"#define ea2h(a) rshift((a),32)\"\n",
      "Warning: Evaluation of preprocessor macros not implemented.\n",
      "\t\"#define ea2l(a) (a)\"\n",
      "Warning: Evaluation of preprocessor directive failed.\n",
      "\t\"#if isdtrace\"\n",
      "768 8\n",
      "FV-hires 0001\n",
      "FV-hires 0067\n",
      "Lg10ENUCbyP 0001\n",
      "Lg10Vort 0001\n",
      "TanhDivU 0001\n",
      "TanhUY 0001\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "in_dir = 'smaller_dir_for_tests2'\n",
    "out_dir = 'hv-files-old-format'\n",
    "reformat_parallel(in_dir,out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'copy_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-248dbe76d729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdirs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jerichoo/jupyter_py3/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jerichoo/jupyter_py3/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchedCalls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                 \u001b[0;31m# No more tasks available in the iterator: tell caller to stop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jerichoo/jupyter_py3/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterator_slice)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-248dbe76d729>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((dirs,))\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdirs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: global name 'copy_files' is not defined"
     ]
    }
   ],
   "source": [
    "source_dir = [\n",
    "    'LowZAGB-22.5xheat-burn-256-old-code-copy',\n",
    "    'LowZAGB-22.5xheat-burn-256-old-code'\n",
    "            ]\n",
    "all_files=False\n",
    "max_dumps=None\n",
    "num_cores = mp.cpu_count()\n",
    "\n",
    "Parallel(n_jobs=1)(delayed(copy_files)(dirs,6) for dirs in source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named joblib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aac54f87566a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named joblib"
     ]
    }
   ],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/scratch/jerichoo/PPM_J5/PPM2F-star_J4.F', '/scratch/jerichoo/PPM_J5/PPM2F-star_J5.F']\n",
      "one\n",
      "J4.F J5.F\n",
      "Warning: Evaluation of preprocessor directive failed.\n",
      "\t\"#define nnbsmax nnbuckets/5\"\n",
      "Warning: Evaluation of preprocessor macros not implemented.\n",
      "\t\"#define ea2h(a) rshift((a),32)\"\n",
      "Warning: Evaluation of preprocessor macros not implemented.\n",
      "\t\"#define ea2l(a) (a)\"\n",
      "Warning: Evaluation of preprocessor directive failed.\n",
      "\t\"#if isdtrace\"\n",
      "{'AAtomicNocld': 16.6, 'is6io': 0, 'isX1io': 0, 'nndumpstot': 3000, 'iiglobwrptag': 325000, 'isuyio': 0, 'ixrprhoekurbubble': 31, 'nnbdy': 5, 'isrestart': 0, 'ischeckCourant': 0, 'ccourinitmx': 0.75, 'ggravconst': 6.673e-05, 'isnodivby0': 0, 'RRhoCldToAir0': 1.0, 'isheaton': 1, 'isomp': 1, 'ixrpuy': 12, 'isC12O16on': 0, 'rrhoabove': 1.0, 'ixrpuz': 13, 'ixrpp': 9, 'iiglobtrptag': 320000, 'ixrprhoeiurbubble': 32, 'nnnny': 32, 'nnnnx': 32, 'nnnnz': 32, 'isdttrace': 0, 'isZ1io': 0, 'isrpnetdebug': 0, 'ixrprhohurspike': 42, 'ixrprhoekurspike': 40, 'expheatdr': 0.05, 'ggrav00base': 9.0219, 'isalsoN13decay': 0, 'isdtvariable': 0, 'ispert': 0, 'isover2GB': 0, 'ffbigassnumber': 10000000000.0, 'qC12C12MeV': 3.19, 'nnsplitlevels': 1, 'ixrprhoekt': 20, 'isC12C12on': 0, 'ggammaabove': 1.3, 'isuzio': 0, 'isamntburnedvisdasuz': 1, 'ffkcld': 0.187, 'isO16O16on': 0, 'ffkair': 0.54, 'isintelfortran': 1, 'isneutrinoon': 0, 'nnsugar': 2, 'ixrpdy': 18, 'ixrprhoektbubble': 29, 'rradmax': 9.8, 'isX2io': 0, 'isuxio': 0, 'ggammabelow': 1.05, 'ixrprho': 7, 'ixrprhoekrbubble': 30, 'rradout0': 9.5, 'sizeof_int': 4, 'ccourmxhi': 0.8, 'ixrpux': 11, 'iirptag': 310000, 'nntybricks': 6, 'ixrprhospike': 34, 'isPPMvio': 0, 'isMach1plus': 1, 'ixrprhoekr': 21, 'ddtfactor': 1.0, 'rradtop': 7.934799999999999, 'rradinner': 3.5, 'isnullwrites': 0, 'isnotused': 1, 'isfvhiresAMD': 0, 'isnodivby0really': 0, 'rrhoconv': 1.0, 'ixrprhoektspike': 38, 'iirpteamconftag': 305000, 'nndumpstodo': 500, 'isY1io': 0, 'isvectorlogs': 0, 'ispio': 0, 'ggammaconv': 1.6666666666666667, 'ssoundcrossings': 7699.610870393028, 'rrho00base': 1820.94, 'sizeof_int2': 2, 'isrpdebug': 0, 'isPPMio': 0, 'ixrpcounts': 43, 'ismuffledbdry': 0, 'isC12pgon': 0, 'ixrprhobubble': 25, 'is32bit': 0, 'nnhalfwaves': 5, 'sizeof_float': 8, 'nndumpsperrestartdump': 10, 'nncpucores': 4, 'isturnburnoff': 1, 'ddlayerbot': 0.5, 'ixrpfnuc': 17, 'nntriags': 80, 'isresetfv': 1, 'nnteamsinbunch': 2, 'nndumpsperfvreset': 3000, 'iisdtag': 330000, 'nnincacheline': 16, 'isprwio': 0, 'ixrprhoek': 19, 'iscompressedFV': 0, 'ixrprhourspike': 36, 'nnzteams': 8, 'istrace': 0, 'nnrpvars': 43, 'iiteamperftag': 340000, 'isTcorrectionon': 0, 'iicourmxdowntag': 355000, 'isprwtest': 0, 'ttotallum': 1133.6062499999998, 'isreflectbdry': 1, 'issmartdiffusion': 0, 'ccldmu': 1.848, 'istimestamp': 1, 'nnyteams': 8, 'ddlayertop': 0.25, 'isY2io': 0, 'ixrpenuc': 16, 'isfvio': 0, 'sizeof_char': 1, 'isZ2io': 0, 'ishiresout': 1, 'iiteamrptag': 315000, 'is48in1': 1, 'AAtomicNoair': 22.5, 'ixrprhoeiur': 23, 'ixrprho1': 8, 'isburningCourant': 1, 'nntzbricks': 6, 'isbeatfreq': 0, 'iirpconftag': 300000, 'ixrpp1': 10, 'israyprofile': 1, 'sizeof_int8': 8, 'nntxbricks': 6, 'rradbase': 4.1297, 'ismessagingtest': 0, 'ixrprhoeiurspike': 41, 'aairmu': 1.848, 'pprs00base': 27647.36, 'ixrprho1spike': 35, 'iicourmxuptag': 350000, 'ixrprhohur': 24, 'ixrprhourbubble': 27, 'QQc12pgammaMEV': 1.944, 'expheatslope': 5.8, 'ccourmxlo': 0.3, 'nnbuckets': 80, 'ixrprho1bubble': 26, 'ixrprhoekur': 22, 'rradin0': 3.0, 'isrhoio': 0, 'isviolent': 1, 'isexpheat': 1, 'ixrprhohurbubble': 33, 'ismsgio': 0, 'isburnonceper2dt': 0, 'ixrprhoekspike': 37, 'iscourmxglobal': 1, 'ixrpfvb': 5, 'issetdtfromddtfactor': 1, 'ixrpfvy': 3, 'ixrpfvt': 6, 'ixrpceul': 14, 'mmaxrad': 10001, 'nncellchunks': 3, 'ixrpmach': 15, 'ixrprhoekrspike': 39, 'isrankio': 0, 'expheatr0': 4.2, 'ixrpfv': 1, 'ddelrad': 0.0009799020097990203, 'ixrpfvyy': 4, 'ixrpfv1': 2, 'ixrprhoekbubble': 28, 'rradouter': 9.2, 'qC12O16MeV': 5.26, 'iiteamsdtag': 335000, 'iskiller': 1}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "import sys\n",
    "sys.path.insert(0,'./moments/moments/utils')\n",
    "sys.path.insert(0,'./moments/')\n",
    "import moments.core.ppmdir\n",
    "import fpp\n",
    "#%%time\n",
    "in_dir = 'PPM_J5'\n",
    "out_dir = 'hv-files'\n",
    "source = moments.core.ppmdir.get_ppmdir(in_dir,False)\n",
    "\n",
    "print source.get_source_code()\n",
    "\n",
    "#analyze PPM2F source code\n",
    "for file in source.get_source_code():\n",
    "    if file.endswith('.F'):\n",
    "        source_code = file\n",
    "        print 'one'\n",
    "        break\n",
    "        \n",
    "print file[-4:], in_dir[-2:]+'.F'\n",
    "b = fpp.preprocess(source_code)\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hv-files-old-format/\n",
      "    compile.sh\n",
      "    jobscript.Orcinus\n",
      "    PPM2F-star_J5.F\n",
      "    HV/\n",
      "        TanhUY/\n",
      "            0001.hv\n",
      "        Lg10Vort/\n",
      "            0001.hv\n",
      "        Lg10ENUCbyP/\n",
      "            0001.hv\n",
      "        FV-hires/\n",
      "            0067.hv\n",
      "            0001.hv\n",
      "        TanhDivU/\n",
      "            0001.hv\n",
      "    FVandMoms48/\n",
      "        0001.bobabb\n",
      "        0001.bobaaa\n",
      "        0001.bobaab\n",
      "        0001.bobbba\n",
      "        0001.bobbab\n",
      "        0001.bobbbb\n",
      "        0001.bobaba\n",
      "        0001.bobbaa\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def last_4chars(x):\n",
    "    return(x[-4:])\n",
    "\n",
    "def list_files(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print('{}{}'.format(subindent, f))\n",
    "            \n",
    "list_files(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -rf hv-files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "num_cores = mp.cpu_count()\n",
    "print num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_dir = 'PPM_J5'\n",
    "out_dir = 'hv-files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
