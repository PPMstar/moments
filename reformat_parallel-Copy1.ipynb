{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jerichoo/jupyter_py3/lib/python2.7/site-packages/')\n",
    "from joblib import Parallel, delayed\n",
    "sys.path.insert(0,'./moments/moments/utils')\n",
    "sys.path.insert(0,'./moments/')\n",
    "import moments.core.ppmdir\n",
    "import fpp\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "log.propagate = False\n",
    "ch = logging.StreamHandler()\n",
    "log.addHandler(ch)\n",
    "log.setLevel(logging.INFO)\n",
    "\n",
    "def reformat_hv(ftype,dump,info):\n",
    "    \n",
    "    #log.info('%s %s  being processed....' % (ftype, dump))\n",
    "    \n",
    "    if os.path.isfile(info.hv_format.format(ftype=ftype, dump=dump, ext=\".hv\")):\n",
    "        log.info('%s %s  already has hv file overwrite=True to overwrite' % (ftype, dump))\n",
    "        return\n",
    "    \n",
    "    for file in info.source.get_dumpfiles(ftype, dump):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        RBO_in_ftype = None\n",
    "        for key, value in info.RBO_input_map.items():\n",
    "            if ftype in key:\n",
    "                RBO_in_ftype = value\n",
    "                break\n",
    "        if RBO_in_ftype is not None:\n",
    "            nbytes = os.path.getsize(file)\n",
    "            nbytes_theoretical = (info.resolutionx*info.resolutiony*info.resolutionz)/info.nteams\n",
    "            out_file = info.hv_processing_format.format(ftype=ftype, RBO_in_ftype=RBO_in_ftype, dump=dump, ext=ext)\n",
    "            \n",
    "            # code to sort out the restarts\n",
    "            if ftype == 'FV-hires':\n",
    "                nbytes_theoretical *= info.nteams # don't know if this is true\n",
    "            if nbytes != nbytes_theoretical:\n",
    "                if nbytes < nbytes_theoretical:\n",
    "                    log.info('bytes: %s this is not the right size should be %s %s %s %s'\\\n",
    "                             % (nbytes, '> ', nbytes_theoretical, ftype, dump))\n",
    "                    break\n",
    "                if nbytes > nbytes_theoretical: \n",
    "                    log.info('bytes: %s %s %s %s %s truncated' % (nbytes, '> ', nbytes_theoretical, ftype, dump))\n",
    "                    out_dir = os.path.dirname(out_file)\n",
    "                    if not os.path.exists(out_dir):\n",
    "                        try:\n",
    "                            os.makedirs(out_dir)\n",
    "                        except:\n",
    "                            log.info('Trying to write to a dir while it was created') \n",
    "\n",
    "                    truncate_command = [\"tail\",\"-c\",str(nbytes_theoretical),file,\">\",out_file]\n",
    "                    command = subprocess.Popen(' '.join(truncate_command), shell=True)\n",
    "                    command.wait()\n",
    "            else:\n",
    "                _copy_file(file, out_file)\n",
    "        else:\n",
    "            log.info('cannot convert {ftype} files into hv'.format(ftype=ftype))\n",
    "            _copy_file(file, info.hv_other_format.format(ftype=ftype, RBO_in_ftype=RBO_in_ftype, dump=dump, ext=ext))\n",
    "            break\n",
    "\n",
    "    for RBO_key in info.RBO_input_map.keys():         \n",
    "        if ftype in RBO_key:\n",
    "            settings = dict((key, info.source_code_definitions.get(key, value)) for key, value in info.RBO_default.items())\n",
    "            settings.update(info.RBO_settings[RBO_key])\n",
    "            \n",
    "            code = fpp.define(info.RBO_source, **settings)\n",
    "            with open(info.hv_source_format.format(ftype=ftype,dump=dump), \"w\") as fout:\n",
    "                fout.write(code)\n",
    "\n",
    "            ftype_RBO_source = info.hv_source_format.format(ftype=ftype,dump=dump)\n",
    "            ftype_RBO, _ = os.path.splitext(ftype_RBO_source)\n",
    "            compile = subprocess.Popen([\"ifort\", ftype_RBO_source] + info.RBO_compile_flags + [ftype_RBO])\n",
    "            compile.wait()\n",
    "\n",
    "            processing_dir = os.path.dirname(info.hv_processing_format.format(ftype=ftype, RBO_in_ftype=\"\", dump=\"\", ext=\"\"))\n",
    "            RBO_command = [ftype_RBO, str(int(dump)), str(int(dump))]\n",
    "\n",
    "            RBO_compute = subprocess.Popen(RBO_command, cwd=processing_dir)\n",
    "            RBO_compute.wait()\n",
    "\n",
    "            bob2hv_ftype = None\n",
    "            for key, value in info.bob2hv_input_map.items():\n",
    "                if ftype in key:\n",
    "                    bob2hv_ftype = value\n",
    "                    break\n",
    "\n",
    "            if bob2hv_ftype is not None:                \n",
    "                resolutionx = info.source_code_definitions[\"nnxteams\"]*info.source_code_definitions[\"nntxbricks\"]*info.source_code_definitions[\"nnnnx\"]\n",
    "                resolutiony = info.source_code_definitions[\"nnyteams\"]*info.source_code_definitions[\"nntybricks\"]*info.source_code_definitions[\"nnnny\"]\n",
    "                resolutionz = info.source_code_definitions[\"nnzteams\"]*info.source_code_definitions[\"nntzbricks\"]*info.source_code_definitions[\"nnnnz\"]\n",
    "                if not any([ftype in type for type in info.is_hires]):\n",
    "                    resolutionx = int(resolutionx/2.0)\n",
    "                    resolutiony = int(resolutiony/2.0)\n",
    "                    resolutionz = int(resolutionz/2.0)\n",
    "                    RBO_file = info.hv_processing_format.format(ftype=ftype, RBO_in_ftype=bob2hv_ftype, dump=dump, ext=\".bobaaa\")\n",
    "                else:\n",
    "                    RBO_file = info.hv_processing_format.format(ftype=ftype, RBO_in_ftype=bob2hv_ftype, dump=dump, ext=\".bob8aaa\")\n",
    "            \n",
    "                bob2hv_command = [info.bob2hv_path, str(resolutionx), str(resolutiony), str(int(resolutionz/2.0)), RBO_file, \"-t\",\n",
    "                                  str(info.source_code_definitions[\"nnxteams\"]), str(info.source_code_definitions[\"nnyteams\"]), str(2*info.source_code_definitions[\"nnzteams\"]), \"-s\", \"128\"]\n",
    "\n",
    "                bob2hv = subprocess.Popen(bob2hv_command, cwd=processing_dir)\n",
    "                bob2hv.wait()\n",
    "\n",
    "                hv_file, _ = os.path.splitext(RBO_file)\n",
    "                try:\n",
    "                    _move_file(hv_file + \".hv\", info.hv_format.format(ftype=ftype, dump=dump, ext=\".hv\"))\n",
    "                except IOError as error:\n",
    "                    log.error('No .hv file was made for {ftype}'.format(ftype=info.hv_format.format(ftype=ftype, dump=dump, ext=\".hv\")))\n",
    "                    log.error('Either {RBO} or {bob} command failed'.format(RBO=RBO_command,bob =bob2hv_command))\n",
    "                    \n",
    "                    \n",
    "def _copy_file(source, target):\n",
    "    target_dir = os.path.dirname(target)\n",
    "    if not os.path.exists(target_dir):\n",
    "        try:\n",
    "            os.makedirs(target_dir)\n",
    "        except:\n",
    "            log.info('Trying to write to a dir while it was created') \n",
    "    try:\n",
    "        if not os.path.exists(target):\n",
    "            shutil.copy(source, target)\n",
    "            pass\n",
    "    except IOError as error:\n",
    "        print(error)\n",
    "\n",
    "def _move_file(source, target):\n",
    "    target_dir = os.path.dirname(target)\n",
    "    if not os.path.exists(target_dir):\n",
    "        try:\n",
    "            os.makedirs(target_dir)\n",
    "        except:\n",
    "            log.info('Trying to write to a dir while it was created') \n",
    "    if not os.path.exists(target):\n",
    "        shutil.move(source, target)\n",
    "\n",
    "class reformation_info(object):\n",
    "    \n",
    "    def __init__(self,source_dir,target_dir,all_files=False,max_dumps=None):\n",
    "        \n",
    "        #RBO: ReformatBigOutput\n",
    "        self.max_dumps = max_dumps\n",
    "        self.all_files = all_files\n",
    "\n",
    "        if isinstance(source_dir, str):\n",
    "            self.source_dir = os.path.abspath(source_dir) + \"/\"\n",
    "            self.source = moments.core.ppmdir.get_ppmdir(source_dir, all_files)\n",
    "        else:\n",
    "            self.source = source_dir\n",
    "            self.source_dir = source._dir\n",
    "\n",
    "        self.target_dir = os.path.abspath(target_dir) + \"/\"\n",
    "        '''\n",
    "        self.profile_format = self.target_dir + \"{ftype}/{ftype}-{dump}{ext}\"\n",
    "        self.bobfile_format = self.target_dir + \"{ftype}/{dump}{ext}\" #chan\n",
    "        self.ppmin_format = self.target_dir + \"post/{fname}\"\n",
    "        self.hv_format = self.target_dir + \"HV/{ftype}/{dump}{ext}\"\n",
    "        self.hv_processing_format = self.target_dir + \"HV_processing/{ftype}/{RBO_in_ftype}-{dump}{ext}\"\n",
    "        self.hv_source_format = self.target_dir + \"HV_processing/{ftype}{dump}_xreformat64_all.F\"\n",
    "        '''\n",
    "        self.profile_format = self.target_dir + \"{ftype}/{ftype}-{dump}{ext}\"\n",
    "        self.bobfile_format = self.target_dir + \"{ftype}/{dump}/{ftype}-{dump}{ext}\" #chan\n",
    "        self.ppmin_format = self.target_dir + \"post/{fname}\"\n",
    "        self.hv_format = self.target_dir + \"HV/{ftype}/{ftype}-{dump}{ext}\"\n",
    "        self.hv_processing_format = self.target_dir + \"HV_processing/{ftype}/{RBO_in_ftype}-{dump}{ext}\"\n",
    "        self.hv_other_format = self.target_dir + \"other_bob/{ftype}/{RBO_in_ftype}-{dump}{ext}\"\n",
    "        self.hv_source_format = self.target_dir + \"HV_processing/{ftype}{dump}_xreformat64_all.F\"\n",
    "\n",
    "        self.RBO_source = pkg_resources.resource_string(\"moments.utils\", \"/bin/ReformatBigOutputargs.F\")\n",
    "        self.RBO_compile_flags = [\"-mcmodel=medium\", \"-i-dynamic\", \"-tpp7\", \"-xT\", \"-fpe0\",\n",
    "                             \"-w\", \"-ip\", \"-Ob2\", \"-pc32\", \"-i8\", \"-auto\", \"-fpp2\", \"-o\"]\n",
    "\n",
    "        self.RBO_input_map = {\"FVandMoms\":\"FVandMoms48\",\n",
    "                         \"FV-hires\":\"FV-hires01\",\n",
    "                         \"TanhUY\":\"TanhUY--001\",\n",
    "                         \"TanhDivU\":\"TanhDivU-01\",\n",
    "                         \"Lg10Vort\":\"Lg10Vort-01\",\n",
    "                         \"Lg10ENUCbyP\":\"Lg10ENUCbyP\"}\n",
    "\n",
    "        self.RBO_default = {\"isBoB8\":0, \"isBoB\":0, \"isMom\":0, \"isvort\":0,\n",
    "                       \"isdivu\":0, \"isuy\":0, \"isenuc\":0, \"nnxteams\":0,\n",
    "                       \"nnyteams\":0, \"nnzteams\":0, \"nntxbricks\":0,\n",
    "                       \"nntybricks\":0, \"nntzbricks\":0, \"nnnnx\":0,\n",
    "                       \"nnnny\":0, \"nnnnz\":0}\n",
    "\n",
    "        self.RBO_settings = {\"FVandMoms\":{\"isMom\":1},\n",
    "                        \"FV-hires\":{\"isBoB8\":1},\n",
    "                        \"TanhUY\":{\"isBoB\":1, \"isuy\":1},\n",
    "                        \"TanhDivU\":{\"isBoB\":1, \"isdivu\":1},\n",
    "                        \"Lg10Vort\":{\"isBoB\":1, \"isvort\":1},\n",
    "                        \"Lg10ENUCbyP\":{\"isBoB\":1, \"isenuc\":1}}\n",
    "\n",
    "        self.bob2hv_path = os.path.abspath(pkg_resources.resource_filename(\"moments.utils\", \"/bin/bob2hv\"))\n",
    "\n",
    "        self.is_hires = [\"FV-hires\"]\n",
    "\n",
    "        self.bob2hv_input_map = {\"FVandMoms\":\"FVandMomt48\",\n",
    "                            \"FV-hires\":\"FV-hiret01\",\n",
    "                            \"TanhUY\":\"TanhUY-0001\",\n",
    "                            \"TanhDivU\":\"TanhDivV-01\",\n",
    "                            \"Lg10Vort\":\"Lg10Voru-01\",\n",
    "                            \"Lg10ENUCbyP\":\"Lg10ENVCbyP\"}\n",
    "\n",
    "        self.profiles = []\n",
    "        self.bobfiles = []\n",
    "        self.ppminfiles = []\n",
    "        self.hvfiles = []\n",
    "\n",
    "        #analyze PPM2F source code\n",
    "        for file in self.source.get_source_code():\n",
    "            if file.endswith(source_dir[-2:]+'.F'):\n",
    "                log.info(file, ' will be used as the source file')\n",
    "                source_code = file\n",
    "                break\n",
    "                \n",
    "        if 'source_code' not in locals():\n",
    "            source_code = self.source.get_source_code()[0]\n",
    "            log.info('%s will be used as the source file' % (file))    \n",
    "        self.source_code_definitions = fpp.preprocess(source_code)\n",
    "        if (\"nnzteams\" in self.source_code_definitions) and (\"nnxteams\" not in self.source_code_definitions):\n",
    "            self.source_code_definitions[\"nnxteams\"] = self.source_code_definitions[\"nnzteams\"]\n",
    "\n",
    "        if (\"nntzbricks\" in self.source_code_definitions) and (\"nntxbricks\" not in self.source_code_definitions):\n",
    "            self.source_code_definitions[\"nntxbricks\"] = self.source_code_definitions[\"nntzbricks\"]\n",
    "\n",
    "        if (\"nnnnz\" in self.source_code_definitions) and (\"nnnnx\" not in self.source_code_definitions):\n",
    "            self.source_code_definitions[\"nnnnx\"] = self.source_code_definitions[\"nnnnz\"] \n",
    "        #move files into HV_processing\n",
    "        self.resolutionx = self.source_code_definitions[\"nnxteams\"]*self.source_code_definitions[\"nntxbricks\"]\\\n",
    "            *self.source_code_definitions[\"nnnnx\"]\n",
    "        self.resolutiony = self.source_code_definitions[\"nnyteams\"]*self.source_code_definitions[\"nntybricks\"]\\\n",
    "            *self.source_code_definitions[\"nnnny\"]\n",
    "        self.resolutionz = self.source_code_definitions[\"nnzteams\"]*self.source_code_definitions[\"nntzbricks\"]\\\n",
    "            *self.source_code_definitions[\"nnnnz\"]\n",
    "        self.nteams = self.source_code_definitions[\"nnxteams\"]*self.source_code_definitions[\"nnyteams\"]\\\n",
    "            *self.source_code_definitions[\"nnzteams\"]\n",
    "        \n",
    "        print self.resolutionx, self.nteams\n",
    "        \n",
    "        self.profiles = self.source.get_profile_types()\n",
    "        for ftype in self.source.get_bobfile_types():\n",
    "            if \"FVandMoms\" in ftype:\n",
    "                self.bobfiles.append(ftype)\n",
    "            else:\n",
    "                self.hvfiles.append(ftype)\n",
    "        self.ppminfiles = self.source.get_ppminfile_types()\n",
    "    \n",
    "def copy_source_code(info,file):\n",
    "    \n",
    "    #for file in info.source.get_source_code() + info.source.get_compile_script() + info.source.get_jobscript() + info.source.get_other_files():\n",
    "    fname = file.replace(info.source_dir, \"\")\n",
    "    _copy_file(file, info.target_dir + fname)\n",
    "        \n",
    "def copy_profiles(info,ftype,dump):\n",
    "    \n",
    "    for file in info.source.get_dumpfiles(ftype, dump):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        _copy_file(file, info.profile_format.format(ftype=ftype, dump=dump, ext=ext))\n",
    "                \n",
    "def copy_bobfiles(info,ftype,dump):\n",
    "    \n",
    "    for file in info.source.get_dumpfiles(ftype, dump):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        _copy_file(file, info.bobfile_format.format(ftype=ftype, dump=dump, ext=ext))\n",
    "                \n",
    "def copy_ppminfiles(info):\n",
    "    \n",
    "    for ftype in info.ppminfiles:\n",
    "        for i, dump in enumerate(info.source.get_dumps(ftype)):\n",
    "            if info.max_dumps is not None:\n",
    "                if i == info.max_dumps:\n",
    "                    break\n",
    "            for file in info.source.get_dumpfiles(ftype, dump):\n",
    "                fname = os.path.basename(file)\n",
    "                _copy_file(file, info.ppmin_format.format(fname=fname))\n",
    "\n",
    "def reformat_parallel(info,target_dir,all_files=False,max_dumps=None):\n",
    "    \n",
    "    #setting up a logger\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "    logs_dir = target_dir + '/reformatting_log'\n",
    "    \n",
    "    if not os.path.exists(logs_dir):\n",
    "        os.makedirs(logs_dir)\n",
    "\n",
    "    fh = logging.FileHandler(os.path.join(logs_dir, 'log_' + target_dir[-2:]))\n",
    "    fh.setFormatter(formatter)\n",
    "    log.addHandler(fh)\n",
    "    \n",
    "    # copy_only(info)\n",
    "    other_files = (\n",
    "                    info.source.get_source_code() \n",
    "                    + info.source.get_compile_script() \n",
    "                    + info.source.get_jobscript()\n",
    "                    + info.source.get_other_files())\n",
    "    \n",
    "    copy_ppminfiles(info)\n",
    "    \n",
    "    num_cores = mp.cpu_count() #this always returns 32\n",
    "\n",
    "    # Running the copy process in parallel\n",
    "    Parallel(n_jobs=num_cores)(\n",
    "        delayed(copy_source_code)(info,file) for file in other_files)\n",
    "   \n",
    "    Parallel(n_jobs=num_cores)(\n",
    "        delayed(copy_profiles)(info,ftype,ndump) for ftype in info.profiles\\\n",
    "        for ndump in info.source.get_dumps(ftype))\n",
    "    \n",
    "    Parallel(n_jobs=num_cores)(\n",
    "        delayed(copy_bobfiles)(info,ftype,ndump) for ftype in info.bobfiles\\\n",
    "        for ndump in info.source.get_dumps(ftype))\n",
    "\n",
    "    # Running the hv transformation in parallel\n",
    "    Parallel(n_jobs=num_cores)(\n",
    "        delayed(reformat_hv)(ftype,ndump,info) for ftype in info.hvfiles\\\n",
    "        for ndump in info.source.get_dumps(ftype))\n",
    "                        \n",
    "    shutil.rmtree(os.path.dirname(info.hv_source_format.format(ftype=\"\",dump=\"\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing a run to redo it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!rm -rf /home/jerichoo/projects/rrg-fherwig-ad/fherwig/PPM_processed/D/pPPM_D6/HV_processing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerichoo/projects/rrg-fherwig-ad/fherwig/PPM_unprocessed/I/PPM_I3/PPM2F-star_I3.F~ will be used as the source file\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'nnxteams'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7fcbcfa1dc99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mout_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/jerichoo/projects/rrg-fherwig-ad/fherwig/PPM_processed/D/pPPM_I3'\u001b[0m \u001b[0;31m#.format(name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreformation_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_dumps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mreformat_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-d083a0dff2a6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source_dir, target_dir, all_files, max_dumps)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_code_definitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nnnnx\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_code_definitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nnnnz\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m#move files into HV_processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolutionx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_code_definitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nnxteams\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_code_definitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nntxbricks\"\u001b[0m\u001b[0;34m]\u001b[0m            \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_code_definitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nnnnx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolutiony\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_code_definitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nnyteams\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_code_definitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nntybricks\"\u001b[0m\u001b[0;34m]\u001b[0m            \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_code_definitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nnnny\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolutionz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_code_definitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nnzteams\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_code_definitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nntzbricks\"\u001b[0m\u001b[0;34m]\u001b[0m            \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_code_definitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nnnnz\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'nnxteams'"
     ]
    }
   ],
   "source": [
    "#for name in [8,5,7,9,15]:\n",
    "#    try:\n",
    "#in_dir = '/home/jerichoo/projects/rrg-fherwig-ad/fherwig/PPM_unprocessed/PPM_D5.format(name)\n",
    "#out_dir = '/home/jerichoo/projects/rrg-fherwig-ad/fherwig/PPM_processed/D/pPPM_D5' #.format(name)\n",
    "in_dir = '/home/jerichoo/projects/rrg-fherwig-ad/fherwig/PPM_unprocessed/I/PPM_I3/' #.format(name)\n",
    "out_dir = '/home/jerichoo/projects/rrg-fherwig-ad/fherwig/PPM_processed/I/pPPM_I3' #.format(name)\n",
    "\n",
    "info = reformation_info(in_dir,out_dir,all_files=True,max_dumps=None)\n",
    "\n",
    "reformat_parallel(info,out_dir,all_files = True)\n",
    "#    except:\n",
    "\n",
    "#        print('Didnt make hv for {}'.format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the file structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def list_files(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "            \n",
    "list_files(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the files were moved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_files(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files[1:10]:\n",
    "            print('{}{}'.format(subindent, f))\n",
    "            \n",
    "list_files(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -lat pPPM_D4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod -R o-r pPPM_D4/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send a random sample to helix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cedar=c99fd40c-5545-11e7-beb6-22000b9a448b\n",
    "helix=de463ce4-6d04-11e5-ba46-22000b92c6ec\n",
    "globus transfer $cedar:/scratch/jerichoo/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
